{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PoetryCharByChar",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/katarinagresova/M7DataSP_2020/blob/main/assignment_07/PoetryCharByChar.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V2T2RYNFMbgf"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "This notebook is inspired by [Keras example](https://keras.io/examples/generative/lstm_character_level_text_generation/) on generating text from Nietzsche's writings with a character-level LSTM. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4mGTPueMbgf"
      },
      "source": [
        "## Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cVKtzaHMbgf"
      },
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "import numpy as np\n",
        "import random\n",
        "import io\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZECMxNcMbgg"
      },
      "source": [
        "## Prepare the data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMHgYOriMbgg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d543edc-49c6-4db0-896a-dc4283900657"
      },
      "source": [
        "path = keras.utils.get_file(\n",
        "    \"emily-together.txt\", origin=\"https://raw.githubusercontent.com/katarinagresova/M7DataSP_2020/main/assignment_07/data/emily-together.txt\"\n",
        ")\n",
        "with io.open(path, encoding=\"utf-8\") as f:\n",
        "    text = f.read().lower()\n",
        "print(\"Corpus length:\", len(text))\n",
        "\n",
        "chars = sorted(list(set(text)))\n",
        "print(\"Total chars:\", len(chars))\n",
        "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
        "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
        "\n",
        "# cut the text in semi-redundant sequences of maxlen characters\n",
        "maxlen = 20\n",
        "step = 3\n",
        "sentences = []\n",
        "next_chars = []\n",
        "for i in range(0, len(text) - maxlen, step):\n",
        "    sentences.append(text[i : i + maxlen])\n",
        "    next_chars.append(text[i + maxlen])\n",
        "print(\"Number of sequences:\", len(sentences))\n",
        "\n",
        "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
        "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
        "for i, sentence in enumerate(sentences):\n",
        "    for t, char in enumerate(sentence):\n",
        "        x[i, t, char_indices[char]] = 1\n",
        "    y[i, char_indices[next_chars[i]]] = 1\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://raw.githubusercontent.com/katarinagresova/M7DataSP_2020/main/assignment_07/data/emily-together.txt\n",
            "188416/184901 [==============================] - 0s 0us/step\n",
            "Corpus length: 183924\n",
            "Total chars: 42\n",
            "Number of sequences: 61302\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QPwpLPRzMbgg"
      },
      "source": [
        "## Build the model: a single LSTM layer\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tuTV9C3Mbgg"
      },
      "source": [
        "model = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=(maxlen, len(chars))),\n",
        "        layers.LSTM(128, return_sequences=True),\n",
        "        layers.LSTM(128, return_sequences=False),\n",
        "        layers.Dense(len(chars), activation=\"softmax\"),\n",
        "    ]\n",
        ")\n",
        "optimizer = keras.optimizers.RMSprop(learning_rate=0.01)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer)\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XIG36c6gMbgg"
      },
      "source": [
        "## Prepare the text sampling function\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AzXnxz-NMbgg"
      },
      "source": [
        "\n",
        "def sample(preds, temperature=1.0):\n",
        "    # helper function to sample an index from a probability array\n",
        "    preds = np.asarray(preds).astype(\"float64\")\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gyn78he9Mbgg"
      },
      "source": [
        "## Train the model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cWKn_SKBPAmj",
        "outputId": "9bc582af-045a-48b7-dc67-625badb11868"
      },
      "source": [
        "epochs = 40\n",
        "batch_size = 128\n",
        "\n",
        "model.fit(x, y, batch_size=batch_size, epochs=epochs)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "479/479 [==============================] - 3s 7ms/step - loss: 2.3811\n",
            "Epoch 2/40\n",
            "479/479 [==============================] - 3s 7ms/step - loss: 1.9360\n",
            "Epoch 3/40\n",
            "479/479 [==============================] - 3s 7ms/step - loss: 1.7890\n",
            "Epoch 4/40\n",
            "479/479 [==============================] - 3s 7ms/step - loss: 1.6833\n",
            "Epoch 5/40\n",
            "479/479 [==============================] - 3s 7ms/step - loss: 1.6008\n",
            "Epoch 6/40\n",
            "479/479 [==============================] - 3s 7ms/step - loss: 1.5258\n",
            "Epoch 7/40\n",
            "479/479 [==============================] - 3s 7ms/step - loss: 1.4612\n",
            "Epoch 8/40\n",
            "479/479 [==============================] - 3s 7ms/step - loss: 1.3981\n",
            "Epoch 9/40\n",
            "479/479 [==============================] - 3s 7ms/step - loss: 1.3481\n",
            "Epoch 10/40\n",
            "479/479 [==============================] - 3s 7ms/step - loss: 1.3056\n",
            "Epoch 11/40\n",
            "479/479 [==============================] - 3s 7ms/step - loss: 1.2641\n",
            "Epoch 12/40\n",
            "479/479 [==============================] - 3s 7ms/step - loss: 1.2290\n",
            "Epoch 13/40\n",
            "479/479 [==============================] - 3s 7ms/step - loss: 1.1961\n",
            "Epoch 14/40\n",
            "479/479 [==============================] - 3s 7ms/step - loss: 1.1630\n",
            "Epoch 15/40\n",
            "479/479 [==============================] - 3s 7ms/step - loss: 1.1429\n",
            "Epoch 16/40\n",
            "479/479 [==============================] - 3s 7ms/step - loss: 1.1217\n",
            "Epoch 17/40\n",
            "479/479 [==============================] - 3s 7ms/step - loss: 1.0988\n",
            "Epoch 18/40\n",
            "479/479 [==============================] - 3s 7ms/step - loss: 1.0790\n",
            "Epoch 19/40\n",
            "479/479 [==============================] - 3s 7ms/step - loss: 1.0605\n",
            "Epoch 20/40\n",
            "479/479 [==============================] - 3s 7ms/step - loss: 1.0376\n",
            "Epoch 21/40\n",
            "479/479 [==============================] - 3s 7ms/step - loss: 1.0251\n",
            "Epoch 22/40\n",
            "479/479 [==============================] - 3s 7ms/step - loss: 1.0033\n",
            "Epoch 23/40\n",
            "479/479 [==============================] - 3s 7ms/step - loss: 0.9860\n",
            "Epoch 24/40\n",
            "479/479 [==============================] - 3s 7ms/step - loss: 0.9707\n",
            "Epoch 25/40\n",
            "479/479 [==============================] - 3s 7ms/step - loss: 0.9522\n",
            "Epoch 26/40\n",
            "479/479 [==============================] - 3s 7ms/step - loss: 0.9376\n",
            "Epoch 27/40\n",
            "479/479 [==============================] - 3s 7ms/step - loss: 0.9212\n",
            "Epoch 28/40\n",
            "479/479 [==============================] - 3s 7ms/step - loss: 0.9096\n",
            "Epoch 29/40\n",
            "479/479 [==============================] - 3s 7ms/step - loss: 0.8946\n",
            "Epoch 30/40\n",
            "479/479 [==============================] - 3s 7ms/step - loss: 0.8865\n",
            "Epoch 31/40\n",
            "479/479 [==============================] - 3s 7ms/step - loss: 0.8702\n",
            "Epoch 32/40\n",
            "479/479 [==============================] - 3s 7ms/step - loss: 0.8605\n",
            "Epoch 33/40\n",
            "479/479 [==============================] - 3s 7ms/step - loss: 0.8377\n",
            "Epoch 34/40\n",
            "479/479 [==============================] - 3s 7ms/step - loss: 0.8265\n",
            "Epoch 35/40\n",
            "479/479 [==============================] - 3s 7ms/step - loss: 0.8273\n",
            "Epoch 36/40\n",
            "479/479 [==============================] - 3s 7ms/step - loss: 0.8091\n",
            "Epoch 37/40\n",
            "479/479 [==============================] - 3s 7ms/step - loss: 0.7992\n",
            "Epoch 38/40\n",
            "479/479 [==============================] - 3s 7ms/step - loss: 0.7859\n",
            "Epoch 39/40\n",
            "479/479 [==============================] - 3s 7ms/step - loss: 0.7752\n",
            "Epoch 40/40\n",
            "479/479 [==============================] - 3s 7ms/step - loss: 0.7666\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb65e7fcc50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ws5zlKhxPP0K",
        "outputId": "d0b7fce9-8bcd-43b9-935e-4bfe679050b6"
      },
      "source": [
        "for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
        "  print(\"...Diversity:\", diversity)\n",
        "\n",
        "  generated = \"\"\n",
        "  #sentence = text[start_index : start_index + maxlen]\n",
        "  sentence = 'sunshine'\n",
        "  pad_len = maxlen - len(sentence)\n",
        "  if pad_len < 0:\n",
        "    sentence = sentence[:maxlen]\n",
        "  elif pad_len > 0:\n",
        "      sentence = \" \" * (pad_len - 1) + sentence + \".\"\n",
        "\n",
        "  print('...Generating with seed: \"' + sentence + '\"')\n",
        "\n",
        "  for i in range(200):\n",
        "      x_pred = np.zeros((1, maxlen, len(chars)))\n",
        "      for t, char in enumerate(sentence):\n",
        "          x_pred[0, t, char_indices[char]] = 1.0\n",
        "      preds = model.predict(x_pred, verbose=0)[0]\n",
        "      next_index = sample(preds, diversity)\n",
        "      next_char = indices_char[next_index]\n",
        "      sentence = sentence[1:] + next_char\n",
        "      generated += next_char\n",
        "\n",
        "\n",
        "\n",
        "  print(\"...Generated: \", generated)\n",
        "  print()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "...Diversity: 0.2\n",
            "...Generating with seed: \"           sunshine.\"\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: RuntimeWarning: divide by zero encountered in log\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "...Generated:  \n",
            "le such a sunset's, they we stranger!\n",
            "may sile spirig and fut me,\n",
            "and superfluous the rose\n",
            "of the dumf of the sunshance\n",
            "not easy to the things\n",
            "that some of the earth\n",
            "an adnew the sunsumed of the actu\n",
            "\n",
            "...Diversity: 0.5\n",
            "...Generating with seed: \"           sunshine.\"\n",
            "...Generated:  \n",
            "lew, before the sea!\n",
            "put the morning nest,—\n",
            "alond babzled the stood unto\n",
            "with the summer's earless to me.\n",
            "and then it bee of men\n",
            "the dows creator's day;\n",
            "but hight it is dunsich,\n",
            "where she steps contr\n",
            "\n",
            "...Diversity: 1.0\n",
            "...Generating with seed: \"           sunshine.\"\n",
            "...Generated:  \n",
            "le kipendent our mine\n",
            "in tas the as the bleakes of its,\n",
            "and whose his again down,\n",
            "and sun fortrime, i before me\n",
            "the eallow was it happioy.\n",
            "'t was curing of the ended\n",
            "depurting sail a land.\n",
            "it\n",
            "whill h\n",
            "\n",
            "...Diversity: 1.2\n",
            "...Generating with seed: \"           sunshine.\"\n",
            "...Generated:  \n",
            "curtion feet flutter than there.\n",
            "whoser must have riving the garies,\n",
            "when the that distrank of all\n",
            "the other shut the groon;\n",
            "that remores tiety!\n",
            "there was be every sunign she reiendons she have bliew\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}