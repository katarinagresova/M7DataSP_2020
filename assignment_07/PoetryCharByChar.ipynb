{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PoetryCharByChar",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/katarinagresova/M7DataSP_2020/blob/erik/assignment_07/PoetryCharByChar.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V2T2RYNFMbgf"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "This notebook is inspired by [Keras example](https://keras.io/examples/generative/lstm_character_level_text_generation/) on generating text from Nietzsche's writings with a character-level LSTM. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4mGTPueMbgf"
      },
      "source": [
        "## Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cVKtzaHMbgf"
      },
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "import numpy as np\n",
        "import random\n",
        "import io\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZECMxNcMbgg"
      },
      "source": [
        "## Prepare the data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMHgYOriMbgg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d543edc-49c6-4db0-896a-dc4283900657"
      },
      "source": [
        "path = keras.utils.get_file(\n",
        "    \"emily-together.txt\", origin=\"https://raw.githubusercontent.com/katarinagresova/M7DataSP_2020/main/assignment_07/data/emily-together.txt\"\n",
        ")\n",
        "with io.open(path, encoding=\"utf-8\") as f:\n",
        "    text = f.read().lower()\n",
        "print(\"Corpus length:\", len(text))\n",
        "\n",
        "chars = sorted(list(set(text)))\n",
        "print(\"Total chars:\", len(chars))\n",
        "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
        "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
        "\n",
        "# cut the text in semi-redundant sequences of maxlen characters\n",
        "maxlen = 20\n",
        "step = 3\n",
        "sentences = []\n",
        "next_chars = []\n",
        "for i in range(0, len(text) - maxlen, step):\n",
        "    sentences.append(text[i : i + maxlen])\n",
        "    next_chars.append(text[i + maxlen])\n",
        "print(\"Number of sequences:\", len(sentences))\n",
        "\n",
        "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
        "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
        "for i, sentence in enumerate(sentences):\n",
        "    for t, char in enumerate(sentence):\n",
        "        x[i, t, char_indices[char]] = 1\n",
        "    y[i, char_indices[next_chars[i]]] = 1\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://raw.githubusercontent.com/katarinagresova/M7DataSP_2020/main/assignment_07/data/emily-together.txt\n",
            "188416/184901 [==============================] - 0s 0us/step\n",
            "Corpus length: 183924\n",
            "Total chars: 42\n",
            "Number of sequences: 61302\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QPwpLPRzMbgg"
      },
      "source": [
        "## Build the model: two LSTM layers\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tuTV9C3Mbgg"
      },
      "source": [
        "model = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=(maxlen, len(chars))),\n",
        "        layers.LSTM(128, return_sequences=True),\n",
        "        layers.LSTM(128, return_sequences=False),\n",
        "        layers.Dense(len(chars), activation=\"softmax\"),\n",
        "    ]\n",
        ")\n",
        "optimizer = keras.optimizers.RMSprop(learning_rate=0.01)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer)\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XIG36c6gMbgg"
      },
      "source": [
        "## Prepare the text sampling function\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AzXnxz-NMbgg"
      },
      "source": [
        "\n",
        "def sample(preds, temperature=1.0):\n",
        "    # helper function to sample an index from a probability array\n",
        "    preds = np.asarray(preds).astype(\"float64\")\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gyn78he9Mbgg"
      },
      "source": [
        "## Train the model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cWKn_SKBPAmj",
        "outputId": "7db64a49-4751-44ef-a406-7a75b73d43c7"
      },
      "source": [
        "epochs = 40\n",
        "batch_size = 128\n",
        "\n",
        "model.fit(x, y, batch_size=batch_size, epochs=epochs)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "479/479 [==============================] - 3s 7ms/step - loss: 0.7627\n",
            "Epoch 2/40\n",
            "479/479 [==============================] - 3s 7ms/step - loss: 0.7484\n",
            "Epoch 3/40\n",
            "479/479 [==============================] - 3s 7ms/step - loss: 0.7400\n",
            "Epoch 4/40\n",
            "479/479 [==============================] - 3s 7ms/step - loss: 0.7255\n",
            "Epoch 5/40\n",
            "479/479 [==============================] - 3s 7ms/step - loss: 0.7175\n",
            "Epoch 6/40\n",
            "479/479 [==============================] - 3s 7ms/step - loss: 0.7040\n",
            "Epoch 7/40\n",
            "479/479 [==============================] - 3s 7ms/step - loss: 0.6951\n",
            "Epoch 8/40\n",
            "479/479 [==============================] - 3s 7ms/step - loss: 0.6908\n",
            "Epoch 9/40\n",
            "479/479 [==============================] - 3s 7ms/step - loss: 0.6785\n",
            "Epoch 10/40\n",
            "479/479 [==============================] - 3s 7ms/step - loss: 0.6716\n",
            "Epoch 11/40\n",
            "479/479 [==============================] - 3s 7ms/step - loss: 0.6564\n",
            "Epoch 12/40\n",
            "479/479 [==============================] - 3s 7ms/step - loss: 0.6448\n",
            "Epoch 13/40\n",
            "479/479 [==============================] - 3s 7ms/step - loss: 0.6460\n",
            "Epoch 14/40\n",
            "479/479 [==============================] - 3s 7ms/step - loss: 0.6394\n",
            "Epoch 15/40\n",
            "479/479 [==============================] - 3s 7ms/step - loss: 0.6282\n",
            "Epoch 16/40\n",
            "479/479 [==============================] - 3s 7ms/step - loss: 0.6227\n",
            "Epoch 17/40\n",
            "479/479 [==============================] - 3s 7ms/step - loss: 0.6116\n",
            "Epoch 18/40\n",
            "479/479 [==============================] - 3s 7ms/step - loss: 0.6041\n",
            "Epoch 19/40\n",
            "479/479 [==============================] - 3s 7ms/step - loss: 0.6026\n",
            "Epoch 20/40\n",
            "479/479 [==============================] - 3s 7ms/step - loss: 0.5929\n",
            "Epoch 21/40\n",
            "479/479 [==============================] - 3s 7ms/step - loss: 0.5828\n",
            "Epoch 22/40\n",
            "479/479 [==============================] - 3s 7ms/step - loss: 0.5813\n",
            "Epoch 23/40\n",
            "479/479 [==============================] - 3s 7ms/step - loss: 0.5744\n",
            "Epoch 24/40\n",
            "479/479 [==============================] - 3s 7ms/step - loss: 0.5691\n",
            "Epoch 25/40\n",
            "479/479 [==============================] - 3s 7ms/step - loss: 0.5637\n",
            "Epoch 26/40\n",
            "479/479 [==============================] - 3s 7ms/step - loss: 0.5556\n",
            "Epoch 27/40\n",
            "479/479 [==============================] - 3s 7ms/step - loss: 0.5543\n",
            "Epoch 28/40\n",
            "479/479 [==============================] - 3s 7ms/step - loss: 0.5404\n",
            "Epoch 29/40\n",
            "479/479 [==============================] - 3s 7ms/step - loss: 0.5355\n",
            "Epoch 30/40\n",
            "479/479 [==============================] - 3s 7ms/step - loss: 0.5329\n",
            "Epoch 31/40\n",
            "479/479 [==============================] - 3s 7ms/step - loss: 0.5319\n",
            "Epoch 32/40\n",
            "479/479 [==============================] - 3s 7ms/step - loss: 0.5252\n",
            "Epoch 33/40\n",
            "479/479 [==============================] - 3s 7ms/step - loss: 0.5159\n",
            "Epoch 34/40\n",
            "479/479 [==============================] - 3s 7ms/step - loss: 0.5110\n",
            "Epoch 35/40\n",
            "479/479 [==============================] - 3s 7ms/step - loss: 0.5052\n",
            "Epoch 36/40\n",
            "479/479 [==============================] - 3s 7ms/step - loss: 0.4966\n",
            "Epoch 37/40\n",
            "479/479 [==============================] - 3s 7ms/step - loss: 0.4964\n",
            "Epoch 38/40\n",
            "479/479 [==============================] - 3s 7ms/step - loss: 0.4954\n",
            "Epoch 39/40\n",
            "479/479 [==============================] - 3s 7ms/step - loss: 0.4835\n",
            "Epoch 40/40\n",
            "479/479 [==============================] - 3s 7ms/step - loss: 0.4782\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb6667a1048>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ws5zlKhxPP0K",
        "outputId": "21102237-7fad-490c-f32c-e451dad204ca"
      },
      "source": [
        "for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
        "  print(\"...Diversity:\", diversity)\n",
        "\n",
        "  generated = \"\"\n",
        "  sentence = 'sunshine'\n",
        "  pad_len = maxlen - len(sentence)\n",
        "  if pad_len < 0:\n",
        "    sentence = sentence[:maxlen]\n",
        "  elif pad_len > 0:\n",
        "      sentence = \" \" * (pad_len - 1) + sentence + \".\"\n",
        "\n",
        "  print('...Generating with seed: \"' + sentence + '\"')\n",
        "\n",
        "  for i in range(200):\n",
        "      x_pred = np.zeros((1, maxlen, len(chars)))\n",
        "      for t, char in enumerate(sentence):\n",
        "          x_pred[0, t, char_indices[char]] = 1.0\n",
        "      preds = model.predict(x_pred, verbose=0)[0]\n",
        "      next_index = sample(preds, diversity)\n",
        "      next_char = indices_char[next_index]\n",
        "      sentence = sentence[1:] + next_char\n",
        "      generated += next_char\n",
        "\n",
        "\n",
        "\n",
        "  print(\"...Generated: \", generated)\n",
        "  print()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "...Diversity: 0.2\n",
            "...Generating with seed: \"           sunshine.\"\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: RuntimeWarning: divide by zero encountered in log\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "...Generated:  \n",
            "the but they wearing, by.\n",
            "whut that feect their wired\n",
            "and strugg\n",
            "a dack severetion.\n",
            "next to the cracket,\n",
            "and orter of a not can dee,\n",
            "and lote is not be summer.\n",
            "the lusction's a wand.\n",
            "a bird not had t\n",
            "\n",
            "...Diversity: 0.5\n",
            "...Generating with seed: \"           sunshine.\"\n",
            "...Generated:  \n",
            "not pain reverwention\n",
            "an ecstas of the dawn\n",
            "belove the edeal suy,\n",
            "not have i steal of pluse\n",
            "oh, first to gate,\n",
            "countercurious a gold\n",
            "the lady was two lost,\n",
            "we could come suffer door,\n",
            "and prade the ta\n",
            "\n",
            "...Diversity: 1.0\n",
            "...Generating with seed: \"           sunshine.\"\n",
            "...Generated:  \n",
            "not pains unorchan,\n",
            "or first the leaves glady.\n",
            "hout loads flut betted like a wong,\n",
            "or did how many charitly\n",
            "is never kistle coucress be\n",
            "where the meek, swiets upon thy will\n",
            "with untice should de'seld\n",
            "\n",
            "...Diversity: 1.2\n",
            "...Generating with seed: \"           sunshine.\"\n",
            "...Generated:  \n",
            "mort, nort thas i orchard,\n",
            "is dung the reall at the sun;\n",
            "the stuns that frice,\n",
            "pease as every time,\n",
            "to hod his cellours out.\n",
            "thourst rodeb draw here\n",
            "that like a suggled holidsife a long; with a wand,\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}